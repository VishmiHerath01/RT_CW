{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VishmiHerath01/RT_CW/blob/main/CNN_Vishmi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sENDpxlFAbxG",
        "outputId": "7194155d-0d25-4504-a51a-3cc4ce3a62df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'CNNbasedMedicalSegmentation'...\n",
            "remote: Enumerating objects: 73, done.\u001b[K\n",
            "remote: Total 73 (delta 0), reused 0 (delta 0), pack-reused 73 (from 1)\u001b[K\n",
            "Receiving objects: 100% (73/73), 102.44 KiB | 589.00 KiB/s, done.\n",
            "Resolving deltas: 100% (9/9), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/BRML/CNNbasedMedicalSegmentation.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vIVh7oJBELA",
        "outputId": "03bdb607-9b6c-4145-a2b7-2cee805edc2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "586E6MV3sXbF",
        "outputId": "2c7220fc-fa63-4dd6-b122-656ac9e3d08b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cycler==0.11.0 (from -r /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/requirements.txt (line 1))\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl.metadata (785 bytes)\n",
            "Collecting dask==2024.2.0 (from -r /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/requirements.txt (line 2))\n",
            "  Downloading dask-2024.2.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting networkx==3.2.1 (from -r /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/requirements.txt (line 3))\n",
            "  Downloading networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting numpy==1.19.5 (from -r /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/requirements.txt (line 4))\n",
            "  Downloading numpy-1.19.5.zip (7.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pdfkit==1.0.0 (from -r /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/requirements.txt (line 5))\n",
            "  Downloading pdfkit-1.0.0-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: Pillow>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/requirements.txt (line 6)) (11.0.0)\n",
            "Collecting pip==24.0 (from -r /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/requirements.txt (line 7))\n",
            "  Downloading pip-24.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting pyparsing==3.1.1 (from -r /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/requirements.txt (line 8))\n",
            "  Downloading pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: python-dateutil==2.8.2 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/requirements.txt (line 9)) (2.8.2)\n",
            "Collecting PyWavelets==1.5.0 (from -r /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/requirements.txt (line 10))\n",
            "  Downloading pywavelets-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting scikit-image==0.17.2 (from -r /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/requirements.txt (line 11))\n",
            "  Downloading scikit-image-0.17.2.tar.gz (29.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.8/29.8 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ],
      "source": [
        "!pip install -r /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uadpcZNTtMIL"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23o5llmWvw9r",
        "outputId": "955bacf5-7aae-4fb7-d14a-70346893bcea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_329\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_329:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_052\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_052:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_361\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_361:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_068\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_068:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_225\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_225:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_334\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_334:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_157\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_157:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_320\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_320:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_352\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_352:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_115\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_115:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_349\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_349:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_065\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_065:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_099\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_099:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_006\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_006:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_004\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_004:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_038\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_038:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_233\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_233:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_362\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_362:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_359\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_359:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_190\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_190:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_291\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_291:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_092\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_092:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_125\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_125:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_183\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_183:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_010\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_010:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_191\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_191:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_324\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_324:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_169\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_169:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_367\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_367:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_133\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_133:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_094\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_094:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_195\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_195:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_086\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_086:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_296\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_296:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_166\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_166:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_150\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_150:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_317\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_317:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_110\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_110:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_164\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_164:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_144\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_144:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_295\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_295:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_257\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_257:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_298\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_298:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_231\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_231:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_270\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_270:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_326\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_326:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_220\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_220:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_179\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_179:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_345\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_345:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_165\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_165:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_037\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_037:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_358\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_358:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_289\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_289:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_341\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_341:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_240\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_240:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_357\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_357:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_316\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_316:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_188\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_188:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_042\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_042:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_218\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_218:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_228\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_228:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_023\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_023:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_256\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_256:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_197\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_197:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_039\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_039:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_294\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_294:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_275\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_275:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_207\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_207:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_072\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_072:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_071\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_071:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_030\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_030:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_210\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_210:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_034\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_034:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_002\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_002:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_061\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_061:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_182\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_182:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_234\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_234:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_026\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_026:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_060\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_060:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_339\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_339:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_044\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_044:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_276\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_276:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_035\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_035:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_096\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_096:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_184\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_184:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_241\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_241:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_137\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_137:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_011\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_011:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_212\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_212:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_330\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_330:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_251\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_251:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_213\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_213:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_116\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_116:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_266\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_266:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_208\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_208:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_199\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_199:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_353\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_353:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_204\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_204:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_088\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_088:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_315\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_315:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_123\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_123:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_181\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_181:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_045\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_045:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_254\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_254:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_089\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_089:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_265\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_265:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_323\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_323:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_128\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_128:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_114\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_114:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_028\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_028:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_243\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_243:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_105\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_105:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_077\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_077:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_258\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_258:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_189\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_189:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_346\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_346:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_232\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_232:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_264\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_264:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_084\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_084:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_119\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_119:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_278\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_278:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_230\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_230:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_127\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_127:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_152\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_152:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_311\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_311:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_273\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_273:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_020\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_020:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_332\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_332:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_271\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_271:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_103\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_103:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_363\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_363:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_360\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_360:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_246\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_246:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_214\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_214:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_019\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_019:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_198\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_198:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_178\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_178:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_161\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_161:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_365\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_365:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_249\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_249:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_101\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_101:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_005\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_005:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_162\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_162:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_049\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_049:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_147\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_147:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_106\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_106:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_021\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_021:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_018\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_018:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_201\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_201:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_135\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_135:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_160\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_160:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_100\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_100:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_146\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_146:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_056\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_056:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_003\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_003:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_098\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_098:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_001\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_001:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_259\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_259:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_012\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_012:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_217\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_217:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_107\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_107:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_121\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_121:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_280\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_280:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_175\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_175:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_138\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_138:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_306\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_306:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_261\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_261:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "61 images in total.\n",
            "yielding images in range: (0, 61).\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_173\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_173:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_274\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_274:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_129\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_129:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_337\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_337:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_014\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_014:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_272\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_272:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_277\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_277:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_081\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_081:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_227\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_227:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_343\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_343:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_063\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_063:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_282\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_282:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_255\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_255:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_299\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_299:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_325\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_325:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_069\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_069:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_293\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_293:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_288\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_288:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_203\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_203:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_224\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_224:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_252\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_252:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_235\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_235:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_168\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_168:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_076\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_076:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_312\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_312:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_118\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_118:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_269\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_269:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_348\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_348:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_025\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_025:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_029\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_029:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_047\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_047:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_007\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_007:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_027\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_027:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_290\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_290:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_328\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_328:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_055\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_055:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_057\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_057:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_260\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_260:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_307\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_307:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_236\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_236:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_336\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_336:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_267\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_267:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_176\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_176:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_356\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_356:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_142\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_142:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_303\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_303:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_174\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_174:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_209\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_209:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_149\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_149:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_297\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_297:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_136\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_136:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_043\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_043:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_223\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_223:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_177\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_177:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_024\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_024:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_070\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_070:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_344\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_344:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_321\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_321:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_242\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_242:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_308\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_308:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_170\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_170:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "62 images in total.\n",
            "yielding images in range: (0, 62).\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_292\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_292:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_154\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_154:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_347\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_347:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_032\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_032:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_263\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_263:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_244\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_244:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_080\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_080:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_206\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_206:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_226\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_226:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_013\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_013:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_156\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_156:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_287\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_287:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_108\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_108:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_090\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_090:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_048\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_048:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_302\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_302:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_245\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_245:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_141\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_141:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_064\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_064:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_015\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_015:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_050\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_050:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_097\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_097:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_140\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_140:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_279\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_279:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_314\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_314:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_229\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_229:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_335\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_335:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_338\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_338:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_262\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_262:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_237\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_237:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_151\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_151:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_300\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_300:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_051\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_051:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_309\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_309:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_253\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_253:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_354\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_354:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_172\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_172:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_318\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_318:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_331\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_331:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_104\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_104:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_319\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_319:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_281\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_281:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_342\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_342:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_219\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_219:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_248\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_248:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_171\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_171:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_145\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_145:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_016\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_016:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_117\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_117:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_185\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_185:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_031\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_031:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_222\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_222:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_221\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_221:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_284\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_284:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_017\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_017:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_120\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_120:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_250\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_250:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_066\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_066:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_211\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_211:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_305\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_305:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_368\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_368:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_364\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_364:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "building train set\n",
            "246 images in total.\n",
            "yielding images in range: (0, 246).\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_091\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_091:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 1 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_355\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_355:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: False\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/brain_data_scripts/read_images.py:213: UserWarning: Could not find ground truth. Is this a test image?\n",
            "  warnings.warn('Could not find ground truth. Is this a test image?')\n",
            "\tskipping image without ground truth\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_180\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_180:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 2 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_268\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_268:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 3 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_079\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_079:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 4 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_062\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_062:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 5 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_310\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_310:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 6 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_301\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_301:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 7 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_078\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_078:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 8 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_369\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_369:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 9 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_196\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_196:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 10 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_340\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_340:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 11 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_158\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_158:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 12 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_067\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_067:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 13 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_239\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_239:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 14 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_046\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_046:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 15 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_033\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_033:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 16 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_059\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_059:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 17 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_130\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_130:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 18 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_111\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_111:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 19 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_095\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_095:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 20 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_167\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_167:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 21 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_205\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_205:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 22 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_087\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_087:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 23 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_215\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_215:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 24 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_058\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_058:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 25 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_022\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_022:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 26 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_139\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_139:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 27 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_134\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_134:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 28 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_113\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_113:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 29 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_093\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_093:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 30 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_036\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_036:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 31 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_148\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_148:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 32 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_122\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_122:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 33 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_112\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_112:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 34 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_194\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_194:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 35 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_283\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_283:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 36 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_187\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_187:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 37 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_126\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_126:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 38 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_350\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_350:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 39 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_153\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_153:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 40 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_163\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_163:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 41 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_333\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_333:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 42 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_082\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_082:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 43 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_327\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_327:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 44 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_124\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_124:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 45 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_285\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_285:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 46 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_192\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_192:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 47 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_075\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_075:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 48 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_304\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_304:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 49 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_366\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_366:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 50 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_054\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_054:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 51 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_143\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_143:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 52 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_247\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_247:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 53 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_109\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_109:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 54 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_159\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_159:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 55 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_041\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_041:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 56 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_351\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_351:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 57 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_073\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_073:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 58 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_313\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_313:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 59 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_322\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_322:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 60 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_238\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_238:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 61 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_040\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_040:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 62 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_083\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_083:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 63 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_132\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_132:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 64 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_186\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_186:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 65 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_131\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_131:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 66 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_202\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_202:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 67 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_155\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_155:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 68 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_286\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_286:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 69 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_193\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_193:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 70 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_008\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_008:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 71 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_009\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_009:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 72 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_216\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_216:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 73 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_085\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_085:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 74 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_074\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_074:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 75 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_102\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_102:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 76 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_053\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_053:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 77 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_200\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_200:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 78 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_329\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_329:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 79 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_052\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_052:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 80 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_361\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_361:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 81 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_068\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_068:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 82 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_225\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_225:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 83 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_334\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_334:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 84 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_157\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_157:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 85 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_320\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_320:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 86 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_352\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_352:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 87 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_115\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_115:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 88 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_349\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_349:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 89 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_065\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_065:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 90 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_099\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_099:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 91 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_006\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_006:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 92 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_004\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_004:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 93 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_038\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_038:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 94 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_233\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_233:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 95 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_362\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_362:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 96 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_359\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_359:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 97 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_190\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_190:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 98 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_291\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_291:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 99 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_092\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_092:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 100 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_125\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_125:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 101 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_183\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_183:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 102 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_010\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_010:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 103 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_191\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_191:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 104 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_324\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_324:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 105 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_169\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_169:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 106 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_367\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_367:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 107 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_133\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_133:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 108 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_094\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_094:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 109 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_195\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_195:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 110 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_086\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_086:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 111 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_296\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_296:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 112 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_166\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_166:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 113 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_150\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_150:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 114 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_317\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_317:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 115 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_110\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_110:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 116 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_164\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_164:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 117 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_144\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_144:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 118 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_295\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_295:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 119 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_257\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_257:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 120 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_298\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_298:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 121 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_231\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_231:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 122 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_270\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_270:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 123 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_326\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_326:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 124 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_220\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_220:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 125 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_179\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_179:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 126 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_345\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_345:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 127 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_165\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_165:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 128 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_037\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_037:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 129 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_358\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_358:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 130 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_289\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_289:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 131 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_341\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_341:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 132 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_240\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_240:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 133 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_357\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_357:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 134 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_316\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_316:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 135 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_188\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_188:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 136 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_042\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_042:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 137 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_218\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_218:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 138 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_228\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_228:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 139 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_023\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_023:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 140 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_256\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_256:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 141 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_197\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_197:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 142 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_039\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_039:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 143 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_294\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_294:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 144 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_275\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_275:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 145 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_207\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_207:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 146 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_072\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_072:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 147 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_071\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_071:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 148 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_030\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_030:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 149 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_210\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_210:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 150 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_034\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_034:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 151 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_002\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_002:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 152 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_061\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_061:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 153 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_182\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_182:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 154 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_234\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_234:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 155 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_026\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_026:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 156 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_060\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_060:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 157 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_339\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_339:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 158 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_044\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_044:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 159 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_276\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_276:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 160 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_035\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_035:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 161 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_096\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_096:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 162 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_184\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_184:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 163 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_241\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_241:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 164 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_137\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_137:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 165 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_011\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_011:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 166 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_212\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_212:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 167 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_330\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_330:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 168 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_251\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_251:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 169 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_213\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_213:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 170 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_116\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_116:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 171 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_266\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_266:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 172 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_208\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_208:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 173 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_199\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_199:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 174 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_353\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_353:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 175 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_204\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_204:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 176 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_088\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_088:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 177 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_315\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_315:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 178 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_123\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_123:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 179 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_181\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_181:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 180 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_045\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_045:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 181 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_254\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_254:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 182 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_089\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_089:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 183 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_265\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_265:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 184 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_323\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_323:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 185 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_128\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_128:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 186 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_114\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_114:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 187 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_028\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_028:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 188 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_243\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_243:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 189 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_105\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_105:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 190 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_077\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_077:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 191 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_258\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_258:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 192 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_189\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_189:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 193 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_346\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_346:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 194 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_232\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_232:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 195 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_264\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_264:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 196 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_084\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_084:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 197 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_119\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_119:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 198 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_278\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_278:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 199 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_230\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_230:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 200 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_127\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_127:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 201 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_152\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_152:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 202 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_311\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_311:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 203 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_273\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_273:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 204 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_020\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_020:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 205 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_332\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_332:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 206 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_271\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_271:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 207 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_103\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_103:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 208 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_363\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_363:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 209 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_360\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_360:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 210 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_246\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_246:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 211 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_214\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_214:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 212 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_019\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_019:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 213 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_198\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_198:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 214 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_178\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_178:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 215 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_161\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_161:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 216 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_365\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_365:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 217 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_249\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_249:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 218 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_101\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_101:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 219 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_005\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_005:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 220 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_162\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_162:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 221 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_049\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_049:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 222 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_147\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_147:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 223 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_106\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_106:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 224 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_021\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_021:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 225 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_018\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_018:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 226 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_201\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_201:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 227 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_135\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_135:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 228 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_160\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_160:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 229 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_100\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_100:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 230 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_146\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_146:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 231 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_056\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_056:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 232 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_003\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_003:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 233 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_098\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_098:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 234 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_001\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_001:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 235 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_259\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_259:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 236 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_012\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_012:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 237 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_217\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_217:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 238 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_107\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_107:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 239 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_121\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_121:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 240 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_280\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_280:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 241 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_175\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_175:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 242 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_138\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_138:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 243 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_306\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_306:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 244 of 245...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_261\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_261:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 245 of 245...\n",
            "building valid set\n",
            "61 images in total.\n",
            "yielding images in range: (0, 61).\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_173\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_173:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 1 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_274\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_274:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 2 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_129\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_129:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 3 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_337\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_337:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 4 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_014\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_014:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 5 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_272\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_272:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 6 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_277\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_277:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 7 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_081\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_081:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 8 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_227\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_227:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 9 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_343\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_343:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 10 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_063\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_063:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 11 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_282\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_282:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 12 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_255\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_255:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 13 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_299\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_299:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 14 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_325\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_325:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 15 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_069\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_069:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 16 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_293\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_293:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 17 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_288\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_288:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 18 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_203\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_203:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 19 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_224\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_224:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 20 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_252\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_252:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 21 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_235\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_235:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 22 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_168\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_168:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 23 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_076\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_076:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 24 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_312\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_312:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 25 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_118\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_118:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 26 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_269\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_269:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 27 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_348\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_348:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 28 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_025\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_025:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 29 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_029\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_029:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 30 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_047\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_047:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 31 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_007\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_007:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 32 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_027\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_027:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 33 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_290\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_290:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 34 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_328\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_328:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 35 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_055\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_055:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 36 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_057\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_057:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 37 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_260\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_260:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 38 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_307\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_307:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 39 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_236\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_236:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 40 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_336\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_336:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 41 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_267\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_267:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 42 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_176\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_176:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 43 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_356\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_356:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 44 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_142\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_142:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 45 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_303\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_303:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 46 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_174\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_174:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 47 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_209\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_209:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 48 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_149\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_149:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 49 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_297\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_297:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 50 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_136\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_136:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 51 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_043\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_043:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 52 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_223\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_223:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 53 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_177\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_177:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 54 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_024\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_024:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 55 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_070\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_070:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 56 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_344\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_344:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 57 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_321\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_321:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 58 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_242\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_242:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 59 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_308\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_308:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 60 of 61...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_170\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_170:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 61 of 61...\n",
            "building test set\n",
            "62 images in total.\n",
            "yielding images in range: (0, 62).\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_292\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_292:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 1 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_154\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_154:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 2 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_347\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_347:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 3 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_032\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_032:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 4 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_263\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_263:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 5 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_244\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_244:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 6 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_080\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_080:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 7 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_206\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_206:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 8 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_226\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_226:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 9 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_013\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_013:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 10 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_156\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_156:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 11 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_287\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_287:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 12 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_108\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_108:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 13 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_090\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_090:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 14 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_048\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_048:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 15 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_302\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_302:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 16 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_245\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_245:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 17 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_141\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_141:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 18 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_064\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_064:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 19 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_015\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_015:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 20 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_050\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_050:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 21 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_097\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_097:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 22 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_140\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_140:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 23 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_279\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_279:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 24 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_314\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_314:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 25 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_229\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_229:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 26 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_335\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_335:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 27 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_338\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_338:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 28 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_262\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_262:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 29 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_237\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_237:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 30 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_151\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_151:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 31 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_300\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_300:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 32 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_051\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_051:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 33 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_309\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_309:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 34 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_253\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_253:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 35 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_354\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_354:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 36 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_172\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_172:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 37 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_318\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_318:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 38 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_331\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_331:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 39 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_104\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_104:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 40 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_319\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_319:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 41 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_281\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_281:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 42 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_342\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_342:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 43 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_219\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_219:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 44 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_248\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_248:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 45 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_171\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_171:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 46 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_145\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_145:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 47 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_016\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_016:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 48 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_117\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_117:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 49 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_185\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_185:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 50 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_031\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_031:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 51 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_222\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_222:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 52 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_221\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_221:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 53 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_284\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_284:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 54 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_017\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_017:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 55 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_120\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_120:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 56 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_250\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_250:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 57 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_066\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_066:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 58 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_211\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_211:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 59 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_305\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_305:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 60 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_368\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_368:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 61 of 62...\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_364\t\n",
            "Looking for files in /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_364:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\treading image 62 of 62...\n"
          ]
        }
      ],
      "source": [
        "!python /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/brain_data_scripts/read_images.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHvpe3Exzk_W",
        "outputId": "774266e5-b470-4502-d240-d297c73420c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cycler in /usr/local/lib/python3.10/dist-packages (0.11.0)\n",
            "Requirement already satisfied: dask in /usr/local/lib/python3.10/dist-packages (2024.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.10.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.3)\n",
            "Requirement already satisfied: pdfkit in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (10.2.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (3.1.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (2.9.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (2024.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (6.0.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.12.0)\n",
            "Requirement already satisfied: SimpleITK in /usr/local/lib/python3.10/dist-packages (2.3.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (1.16.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (0.12.0)\n",
            "Collecting climin\n",
            "  Downloading climin-0.1a1.tar.gz (38 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement breze (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for breze\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install cycler dask h5py matplotlib networkx numpy pdfkit Pillow pyparsing python-dateutil pytz PyYAML scikit-learn scipy SimpleITK six toolz climin breze gnumpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "6VebW0WWlLr_",
        "outputId": "0b88c709-43ee-47de-87e7-f77998dc4847"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: numpy 1.23.5\n",
            "Uninstalling numpy-1.23.5:\n",
            "  Successfully uninstalled numpy-1.23.5\n",
            "Collecting numpy<1.24.0\n",
            "  Using cached numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Using cached numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "Installing collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.19 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 1.4.20 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 1.27.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.87 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "jax 0.4.33 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "jaxlib 0.4.33 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2024.10.0 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.5\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "44ccc884be6d42648b96c478884c95f0",
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: theano==1.0.5 in /usr/local/lib/python3.10/dist-packages (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from theano==1.0.5) (1.23.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.10/dist-packages (from theano==1.0.5) (1.12.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from theano==1.0.5) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "# Uninstall current numpy\n",
        "!pip uninstall -y numpy\n",
        "\n",
        "# Install an older version of numpy that's compatible with Theano 1.0.5\n",
        "!pip install \"numpy<1.24.0\"\n",
        "\n",
        "# Reinstall theano\n",
        "!pip install \"theano==1.0.5\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HKlIL8O7l3-Q",
        "outputId": "0a4afe1c-192c-463d-bf22-0d889feb9e4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.81)] [1 InRelease 3,626 B/3\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.81)] [Connected to r2u.stat\r                                                                                                    \rHit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Waiting for headers] [Connecte\r                                                                                                    \rGet:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [3 InRelease 0 B/1,581 B 0%] [C\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Connected to ppa.launchpadcont\r                                                                                                    \rGet:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,192 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,525 kB]\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,624 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,738 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,454 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [53.3 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,446 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,514 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,225 kB]\n",
            "Fetched 24.2 MB in 3s (7,047 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libopenblas-dev is already the newest version (0.3.20+ds-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 50 not upgraded.\n",
            "Collecting numpy==1.23.0\n",
            "  Downloading numpy-1.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
            "Downloading numpy-1.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.19 requires numpy>=1.24.4, but you have numpy 1.23.0 which is incompatible.\n",
            "albumentations 1.4.20 requires numpy>=1.24.4, but you have numpy 1.23.0 which is incompatible.\n",
            "bigframes 1.27.0 requires numpy>=1.24.0, but you have numpy 1.23.0 which is incompatible.\n",
            "chex 0.1.87 requires numpy>=1.24.1, but you have numpy 1.23.0 which is incompatible.\n",
            "ibis-framework 9.2.0 requires numpy<3,>=1.23.2, but you have numpy 1.23.0 which is incompatible.\n",
            "jax 0.4.33 requires numpy>=1.24, but you have numpy 1.23.0 which is incompatible.\n",
            "jaxlib 0.4.33 requires numpy>=1.24, but you have numpy 1.23.0 which is incompatible.\n",
            "mizani 0.13.0 requires numpy>=1.23.5, but you have numpy 1.23.0 which is incompatible.\n",
            "pandas-stubs 2.2.2.240909 requires numpy>=1.23.5, but you have numpy 1.23.0 which is incompatible.\n",
            "plotnine 0.14.3 requires numpy>=1.23.5, but you have numpy 1.23.0 which is incompatible.\n",
            "tensorflow 2.17.1 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 1.23.0 which is incompatible.\n",
            "xarray 2024.10.0 requires numpy>=1.24, but you have numpy 1.23.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "6e21d00e05e24046a79f5cbc80ade8d0",
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scipy==1.7.3\n",
            "  Downloading scipy-1.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
            "Collecting numpy<1.23.0,>=1.16.5 (from scipy==1.7.3)\n",
            "  Downloading numpy-1.22.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
            "Downloading scipy-1.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.22.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.0\n",
            "    Uninstalling numpy-1.23.0:\n",
            "      Successfully uninstalled numpy-1.23.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.12.0\n",
            "    Uninstalling scipy-1.12.0:\n",
            "      Successfully uninstalled scipy-1.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.19 requires numpy>=1.24.4, but you have numpy 1.22.4 which is incompatible.\n",
            "albumentations 1.4.20 requires numpy>=1.24.4, but you have numpy 1.22.4 which is incompatible.\n",
            "albumentations 1.4.20 requires scipy>=1.10.0, but you have scipy 1.7.3 which is incompatible.\n",
            "arviz 0.20.0 requires numpy>=1.23.0, but you have numpy 1.22.4 which is incompatible.\n",
            "arviz 0.20.0 requires scipy>=1.9.0, but you have scipy 1.7.3 which is incompatible.\n",
            "astropy 6.1.7 requires numpy>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
            "bigframes 1.27.0 requires numpy>=1.24.0, but you have numpy 1.22.4 which is incompatible.\n",
            "chex 0.1.87 requires numpy>=1.24.1, but you have numpy 1.22.4 which is incompatible.\n",
            "contourpy 1.3.1 requires numpy>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
            "cudf-cu12 24.10.1 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
            "ibis-framework 9.2.0 requires numpy<3,>=1.23.2, but you have numpy 1.22.4 which is incompatible.\n",
            "jax 0.4.33 requires numpy>=1.24, but you have numpy 1.22.4 which is incompatible.\n",
            "jax 0.4.33 requires scipy>=1.10, but you have scipy 1.7.3 which is incompatible.\n",
            "jaxlib 0.4.33 requires numpy>=1.24, but you have numpy 1.22.4 which is incompatible.\n",
            "jaxlib 0.4.33 requires scipy>=1.10, but you have scipy 1.7.3 which is incompatible.\n",
            "mizani 0.13.0 requires numpy>=1.23.5, but you have numpy 1.22.4 which is incompatible.\n",
            "mizani 0.13.0 requires scipy>=1.8.0, but you have scipy 1.7.3 which is incompatible.\n",
            "numexpr 2.10.2 requires numpy>=1.23.0, but you have numpy 1.22.4 which is incompatible.\n",
            "nx-cugraph-cu12 24.10.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
            "pandas-stubs 2.2.2.240909 requires numpy>=1.23.5, but you have numpy 1.22.4 which is incompatible.\n",
            "plotnine 0.14.3 requires numpy>=1.23.5, but you have numpy 1.22.4 which is incompatible.\n",
            "plotnine 0.14.3 requires scipy>=1.8.0, but you have scipy 1.7.3 which is incompatible.\n",
            "pylibraft-cu12 24.10.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
            "rmm-cu12 24.10.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
            "scikit-image 0.24.0 requires numpy>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
            "scikit-image 0.24.0 requires scipy>=1.9, but you have scipy 1.7.3 which is incompatible.\n",
            "statsmodels 0.14.4 requires scipy!=1.9.2,>=1.8, but you have scipy 1.7.3 which is incompatible.\n",
            "tensorflow 2.17.1 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 1.22.4 which is incompatible.\n",
            "xarray 2024.10.0 requires numpy>=1.24, but you have numpy 1.22.4 which is incompatible.\n",
            "xarray-einstats 0.8.0 requires numpy>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
            "xarray-einstats 0.8.0 requires scipy>=1.9, but you have scipy 1.7.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.22.4 scipy-1.7.3\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "48be51a5e7e14f04883f90ea0eddfb61",
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: theano==1.0.5 in /usr/local/lib/python3.10/dist-packages (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from theano==1.0.5) (1.22.4)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.10/dist-packages (from theano==1.0.5) (1.7.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from theano==1.0.5) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "# Install BLAS and other required libraries\n",
        "!apt-get update && apt-get install -y libopenblas-dev\n",
        "\n",
        "# Install numpy with openblas support\n",
        "!pip install numpy==1.23.0\n",
        "\n",
        "# Install scipy (required for blas configuration)\n",
        "!pip install scipy==1.7.3\n",
        "\n",
        "# Set Theano flags for CPU usage (since we're having GPU issues)\n",
        "import os\n",
        "os.environ['THEANO_FLAGS'] = 'device=cpu,floatX=float32,lib.cnmem=0'\n",
        "\n",
        "# Install specific version of Theano that's known to work with these dependencies\n",
        "!pip install \"theano==1.0.5\"\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bh5KhG3rm98p",
        "outputId": "a31b889d-e34e-48cb-f55c-fa2bf4a761d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: numpy 1.22.4\n",
            "Uninstalling numpy-1.22.4:\n",
            "  Successfully uninstalled numpy-1.22.4\n",
            "Found existing installation: scipy 1.7.3\n",
            "Uninstalling scipy-1.7.3:\n",
            "  Successfully uninstalled scipy-1.7.3\n",
            "Found existing installation: Theano 1.0.5\n",
            "Uninstalling Theano-1.0.5:\n",
            "  Successfully uninstalled Theano-1.0.5\n",
            "Collecting numpy==1.22.4\n",
            "  Using cached numpy-1.22.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
            "Using cached numpy-1.22.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "Installing collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 1.4.20 requires scipy>=1.10.0, which is not installed.\n",
            "arviz 0.20.0 requires scipy>=1.9.0, which is not installed.\n",
            "clarabel 0.9.0 requires scipy, which is not installed.\n",
            "cvxpy 1.5.4 requires scipy>=1.1.0, which is not installed.\n",
            "datascience 0.17.6 requires scipy, which is not installed.\n",
            "ecos 2.0.14 requires scipy>=0.9, which is not installed.\n",
            "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, which is not installed.\n",
            "hyperopt 0.2.7 requires scipy, which is not installed.\n",
            "imbalanced-learn 0.12.4 requires scipy>=1.5.0, which is not installed.\n",
            "imgaug 0.4.0 requires scipy, which is not installed.\n",
            "jax 0.4.33 requires scipy>=1.10, which is not installed.\n",
            "jaxlib 0.4.33 requires scipy>=1.10, which is not installed.\n",
            "librosa 0.10.2.post1 requires scipy>=1.2.0, which is not installed.\n",
            "lightgbm 4.5.0 requires scipy, which is not installed.\n",
            "matplotlib-venn 1.1.1 requires scipy, which is not installed.\n",
            "missingno 0.5.2 requires scipy, which is not installed.\n",
            "mizani 0.13.0 requires scipy>=1.8.0, which is not installed.\n",
            "mlxtend 0.23.3 requires scipy>=1.2.1, which is not installed.\n",
            "osqp 0.6.7.post3 requires scipy>=0.13.2, which is not installed.\n",
            "plotnine 0.14.3 requires scipy>=1.8.0, which is not installed.\n",
            "pymc 5.18.2 requires scipy>=1.4.1, which is not installed.\n",
            "pytensor 2.26.3 requires scipy<2,>=1, which is not installed.\n",
            "qdldl 0.1.7.post4 requires scipy>=0.13.2, which is not installed.\n",
            "scikit-image 0.24.0 requires scipy>=1.9, which is not installed.\n",
            "scikit-learn 1.4.0 requires scipy>=1.6.0, which is not installed.\n",
            "scs 3.2.7 requires scipy, which is not installed.\n",
            "sentence-transformers 3.2.1 requires scipy, which is not installed.\n",
            "shap 0.46.0 requires scipy, which is not installed.\n",
            "sklearn-pandas 2.2.0 requires scipy>=1.5.1, which is not installed.\n",
            "statsmodels 0.14.4 requires scipy!=1.9.2,>=1.8, which is not installed.\n",
            "xarray-einstats 0.8.0 requires scipy>=1.9, which is not installed.\n",
            "xgboost 2.1.3 requires scipy, which is not installed.\n",
            "yellowbrick 1.5 requires scipy>=1.0.0, which is not installed.\n",
            "albucore 0.0.19 requires numpy>=1.24.4, but you have numpy 1.22.4 which is incompatible.\n",
            "albumentations 1.4.20 requires numpy>=1.24.4, but you have numpy 1.22.4 which is incompatible.\n",
            "arviz 0.20.0 requires numpy>=1.23.0, but you have numpy 1.22.4 which is incompatible.\n",
            "astropy 6.1.7 requires numpy>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
            "bigframes 1.27.0 requires numpy>=1.24.0, but you have numpy 1.22.4 which is incompatible.\n",
            "chex 0.1.87 requires numpy>=1.24.1, but you have numpy 1.22.4 which is incompatible.\n",
            "contourpy 1.3.1 requires numpy>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
            "cudf-cu12 24.10.1 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
            "ibis-framework 9.2.0 requires numpy<3,>=1.23.2, but you have numpy 1.22.4 which is incompatible.\n",
            "jax 0.4.33 requires numpy>=1.24, but you have numpy 1.22.4 which is incompatible.\n",
            "jaxlib 0.4.33 requires numpy>=1.24, but you have numpy 1.22.4 which is incompatible.\n",
            "mizani 0.13.0 requires numpy>=1.23.5, but you have numpy 1.22.4 which is incompatible.\n",
            "numexpr 2.10.2 requires numpy>=1.23.0, but you have numpy 1.22.4 which is incompatible.\n",
            "nx-cugraph-cu12 24.10.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
            "pandas-stubs 2.2.2.240909 requires numpy>=1.23.5, but you have numpy 1.22.4 which is incompatible.\n",
            "plotnine 0.14.3 requires numpy>=1.23.5, but you have numpy 1.22.4 which is incompatible.\n",
            "pylibraft-cu12 24.10.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
            "rmm-cu12 24.10.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
            "scikit-image 0.24.0 requires numpy>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
            "tensorflow 2.17.1 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 1.22.4 which is incompatible.\n",
            "xarray 2024.10.0 requires numpy>=1.24, but you have numpy 1.22.4 which is incompatible.\n",
            "xarray-einstats 0.8.0 requires numpy>=1.23, but you have numpy 1.22.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.22.4\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "6ee5f3dafba2484f8dd6c52f45c23b66",
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scipy==1.7.3\n",
            "  Using cached scipy-1.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from scipy==1.7.3) (1.22.4)\n",
            "Using cached scipy-1.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.9 MB)\n",
            "Installing collected packages: scipy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 1.4.20 requires numpy>=1.24.4, but you have numpy 1.22.4 which is incompatible.\n",
            "albumentations 1.4.20 requires scipy>=1.10.0, but you have scipy 1.7.3 which is incompatible.\n",
            "arviz 0.20.0 requires numpy>=1.23.0, but you have numpy 1.22.4 which is incompatible.\n",
            "arviz 0.20.0 requires scipy>=1.9.0, but you have scipy 1.7.3 which is incompatible.\n",
            "jax 0.4.33 requires numpy>=1.24, but you have numpy 1.22.4 which is incompatible.\n",
            "jax 0.4.33 requires scipy>=1.10, but you have scipy 1.7.3 which is incompatible.\n",
            "jaxlib 0.4.33 requires numpy>=1.24, but you have numpy 1.22.4 which is incompatible.\n",
            "jaxlib 0.4.33 requires scipy>=1.10, but you have scipy 1.7.3 which is incompatible.\n",
            "mizani 0.13.0 requires numpy>=1.23.5, but you have numpy 1.22.4 which is incompatible.\n",
            "mizani 0.13.0 requires scipy>=1.8.0, but you have scipy 1.7.3 which is incompatible.\n",
            "plotnine 0.14.3 requires numpy>=1.23.5, but you have numpy 1.22.4 which is incompatible.\n",
            "plotnine 0.14.3 requires scipy>=1.8.0, but you have scipy 1.7.3 which is incompatible.\n",
            "scikit-image 0.24.0 requires numpy>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
            "scikit-image 0.24.0 requires scipy>=1.9, but you have scipy 1.7.3 which is incompatible.\n",
            "statsmodels 0.14.4 requires scipy!=1.9.2,>=1.8, but you have scipy 1.7.3 which is incompatible.\n",
            "xarray-einstats 0.8.0 requires numpy>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
            "xarray-einstats 0.8.0 requires scipy>=1.9, but you have scipy 1.7.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed scipy-1.7.3\n",
            "Collecting theano==1.0.5\n",
            "  Using cached Theano-1.0.5-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from theano==1.0.5) (1.22.4)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.10/dist-packages (from theano==1.0.5) (1.7.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from theano==1.0.5) (1.16.0)\n",
            "Installing collected packages: theano\n",
            "Successfully installed theano-1.0.5\n"
          ]
        }
      ],
      "source": [
        "# Configure Theano before importing\n",
        "import os\n",
        "os.environ['THEANO_FLAGS'] = 'device=cpu,floatX=float32,lib.cnmem=0,blas.ldflags=-L/usr/lib/x86_64-linux-gnu -lopenblas'\n",
        "\n",
        "# Uninstall current versions\n",
        "!pip uninstall -y numpy scipy theano\n",
        "\n",
        "# Install compatible versions in the correct order\n",
        "!pip install \"numpy==1.22.4\"  # This version is already installed and working\n",
        "!pip install \"scipy==1.7.3\"   # This version is compatible with numpy 1.22.4\n",
        "!pip install \"theano==1.0.5\"  # This should work with the above versions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNFNNw0mnRj9",
        "outputId": "599638bc-625e-47a8-d955-ca38e99473e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0vIRKWEOtMP6",
        "outputId": "5aa7c723-7227-40d1-8260-df412f9d726d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: cycler==0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (0.11.0)\n",
            "Requirement already satisfied: dask==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (2024.2.0)\n",
            "Requirement already satisfied: networkx==3.2.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (3.2.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (1.22.4)\n",
            "Requirement already satisfied: pdfkit==1.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (1.0.0)\n",
            "Requirement already satisfied: Pillow==10.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (10.2.0)\n",
            "Requirement already satisfied: pip==24.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (24.0)\n",
            "Collecting pyparsing==3.1.1 (from -r requirements.txt (line 8))\n",
            "  Downloading pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting python-dateutil==2.8.2 (from -r requirements.txt (line 9))\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting PyWavelets==1.5.0 (from -r requirements.txt (line 10))\n",
            "  Downloading pywavelets-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: scikit-image>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (0.24.0)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (1.7.3)\n",
            "Requirement already satisfied: six==1.16.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (1.16.0)\n",
            "Collecting tifffile==2024.2.12 (from -r requirements.txt (line 14))\n",
            "  Downloading tifffile-2024.2.12-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: toolz==0.12.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (0.12.0)\n",
            "Requirement already satisfied: wheel==0.42.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (0.42.0)\n",
            "Requirement already satisfied: h5py>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (3.10.0)\n",
            "Requirement already satisfied: matplotlib>=3.4.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 19)) (3.8.2)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 21)) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 22)) (0.20.1+cu121)\n",
            "Requirement already satisfied: SimpleITK>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 23)) (2.3.1)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.10/dist-packages (from dask==2024.2.0->-r requirements.txt (line 2)) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from dask==2024.2.0->-r requirements.txt (line 2)) (3.1.0)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask==2024.2.0->-r requirements.txt (line 2)) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from dask==2024.2.0->-r requirements.txt (line 2)) (24.2)\n",
            "Requirement already satisfied: partd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from dask==2024.2.0->-r requirements.txt (line 2)) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask==2024.2.0->-r requirements.txt (line 2)) (6.0.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask==2024.2.0->-r requirements.txt (line 2)) (8.5.0)\n",
            "Collecting numpy>=1.19.5 (from -r requirements.txt (line 4))\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy>=1.7.0 (from -r requirements.txt (line 12))\n",
            "  Downloading scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.18.3->-r requirements.txt (line 11)) (2.36.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.18.3->-r requirements.txt (line 11)) (0.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.3->-r requirements.txt (line 19)) (1.3.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.3->-r requirements.txt (line 19)) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.3->-r requirements.txt (line 19)) (1.4.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r requirements.txt (line 21)) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r requirements.txt (line 21)) (4.12.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r requirements.txt (line 21)) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r requirements.txt (line 21)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.9.0->-r requirements.txt (line 21)) (1.3.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask==2024.2.0->-r requirements.txt (line 2)) (3.21.0)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd>=1.2.0->dask==2024.2.0->-r requirements.txt (line 2)) (1.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.0->-r requirements.txt (line 21)) (3.0.2)\n",
            "Downloading pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.7/247.7 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pywavelets-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tifffile-2024.2.12-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-dateutil, pyparsing, numpy, tifffile, scipy, PyWavelets\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.9.0\n",
            "    Uninstalling python-dateutil-2.9.0:\n",
            "      Successfully uninstalled python-dateutil-2.9.0\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.1.2\n",
            "    Uninstalling pyparsing-3.1.2:\n",
            "      Successfully uninstalled pyparsing-3.1.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.4\n",
            "    Uninstalling numpy-1.22.4:\n",
            "      Successfully uninstalled numpy-1.22.4\n",
            "  Attempting uninstall: tifffile\n",
            "    Found existing installation: tifffile 2024.9.20\n",
            "    Uninstalling tifffile-2024.9.20:\n",
            "      Successfully uninstalled tifffile-2024.9.20\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.7.3\n",
            "    Uninstalling scipy-1.7.3:\n",
            "      Successfully uninstalled scipy-1.7.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyWavelets-1.5.0 numpy-1.26.4 pyparsing-3.1.1 python-dateutil-2.8.2 scipy-1.14.1 tifffile-2024.2.12\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "82eb0dc4267c4b6dbd8a9af45a97d97b",
              "pip_warning": {
                "packages": [
                  "dateutil"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.81)] [Connected to r2u.stat\r                                                                                                    \rHit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r                                                                                                    \rHit:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.81)] [Connected to r2u.stat\r                                                                                                    \rHit:4 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "\r0% [Connecting to security.ubuntu.com (185.125.190.81)] [Connected to r2u.stat.illinois.edu (192.17.\r                                                                                                    \rHit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connected to ppa.launchpadcontent.net (185.125.190.8\r                                                                                                    \rHit:6 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libopenblas-dev is already the newest version (0.3.20+ds-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 50 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision\n",
        "!pip install -r requirements.txt\n",
        "import os\n",
        "os.environ['MKL_THREADING_LAYER'] = 'GNU'\n",
        "os.environ['THEANO_FLAGS'] = 'blas.ldflags=-lopenblas'\n",
        "!apt-get update && apt-get install -y libopenblas-dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bipoeHv6GBCR",
        "outputId": "0e5bbbd1-1d05-4c85-8948-81049409da23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cycler==0.11.0 (from -r /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/requirements.txt (line 1))\n",
            "  Using cached cycler-0.11.0-py3-none-any.whl.metadata (785 bytes)\n",
            "Collecting dask==2024.2.0 (from -r /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/requirements.txt (line 2))\n",
            "  Using cached dask-2024.2.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting networkx==3.2.1 (from -r /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/requirements.txt (line 3))\n",
            "  Using cached networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting numpy==1.19.5 (from -r /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/requirements.txt (line 4))\n",
            "  Using cached numpy-1.19.5.zip (7.3 MB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pdfkit==1.0.0 (from -r /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/requirements.txt (line 5))\n",
            "  Using cached pdfkit-1.0.0-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: Pillow>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/requirements.txt (line 6)) (11.0.0)\n",
            "Collecting pip==24.0 (from -r /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/requirements.txt (line 7))\n",
            "  Using cached pip-24.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting pyparsing==3.1.1 (from -r /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/requirements.txt (line 8))\n",
            "  Using cached pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: python-dateutil==2.8.2 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/requirements.txt (line 9)) (2.8.2)\n",
            "Collecting PyWavelets==1.5.0 (from -r /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/requirements.txt (line 10))\n",
            "  Using cached pywavelets-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting scikit-image==0.17.2 (from -r /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/requirements.txt (line 11))\n",
            "  Using cached scikit-image-0.17.2.tar.gz (29.8 MB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ],
      "source": [
        "!pip install -r /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scipy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLFJrcaZuBUr",
        "outputId": "af53776b-7c8f-44aa-c890-9f53e1618089"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXgWAnUfzmm-",
        "outputId": "7773402e-48a0-4093-c05c-2bf5d33e8ec6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation\n",
            "gnumpy: failed to import cudamat. Using npmat instead. No GPU will be used.\n",
            "Warning: gnumpy not found, using numpy instead\n",
            "Warning: climin not found, using basic training loop\n",
            "Warning: breze not found, using basic reporting\n",
            "Building model, coach...\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "# # Change to the project directory first\n",
        "# %cd /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/\n",
        "\n",
        "# # Then run the training script\n",
        "# !python3 train.py fcn_rffc4 brats_fold0 brats_fold0 600 -ch False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nibabel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LHMpt0aeYV2",
        "outputId": "c6671ef3-d290-4758-e755-faeb98456f78"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (5.3.2)\n",
            "Requirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.10/dist-packages (from nibabel) (6.4.5)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from nibabel) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.10/dist-packages (from nibabel) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.10/dist-packages (from nibabel) (4.12.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%run \"/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/data/build_dataset.py\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLzYjIy_etQQ",
        "outputId": "71b94775-58d0-4de5-9d68-5a17667d55ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Looking for training data in: /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData\n",
            "Will save dataset to: /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/data/datasets\n",
            "\n",
            "Using 30 samples out of total available\n",
            "\n",
            "Splitting 30 samples into:\n",
            "Training: 21\n",
            "Validation: 4\n",
            "Testing: 5\n",
            "\n",
            "Checking image dimensions...\n",
            "Loading files from /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_001:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "Image dimensions (after downsampling): (120, 120, 78)\n",
            "\n",
            "Processing training data...\n",
            "Processing 1/21: BraTS20_Training_001\n",
            "Loading files from /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_001:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "Processing 2/21: BraTS20_Training_002\n",
            "Loading files from /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_002:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "Processing 3/21: BraTS20_Training_003\n",
            "Loading files from /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_003:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "Processing 4/21: BraTS20_Training_004\n",
            "Loading files from /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_004:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "Processing 5/21: BraTS20_Training_005\n",
            "Loading files from /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_005:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "Processing 6/21: BraTS20_Training_006\n",
            "Loading files from /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_006:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "Processing 7/21: BraTS20_Training_007\n",
            "Loading files from /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_007:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "Processing 8/21: BraTS20_Training_008\n",
            "Loading files from /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_008:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "Processing 9/21: BraTS20_Training_009\n",
            "Loading files from /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_009:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "Processing 10/21: BraTS20_Training_010\n",
            "Loading files from /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_010:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "Processing 11/21: BraTS20_Training_011\n",
            "Loading files from /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_011:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "Processing 12/21: BraTS20_Training_012\n",
            "Loading files from /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_012:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "Processing 13/21: BraTS20_Training_013\n",
            "Loading files from /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_013:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "Processing 14/21: BraTS20_Training_014\n",
            "Loading files from /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_014:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "Processing 15/21: BraTS20_Training_015\n",
            "Loading files from /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_015:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "Processing 16/21: BraTS20_Training_016\n",
            "Loading files from /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_016:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "Processing 17/21: BraTS20_Training_017\n",
            "Loading files from /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_017:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "Processing 18/21: BraTS20_Training_018\n",
            "Loading files from /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_018:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "Processing 19/21: BraTS20_Training_019\n",
            "Loading files from /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_019:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "Processing 20/21: BraTS20_Training_020\n",
            "Loading files from /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_020:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "Processing 21/21: BraTS20_Training_021\n",
            "Loading files from /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_021:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\n",
            "Processing validation data...\n",
            "Processing 1/4: BraTS20_Training_022\n",
            "Loading files from /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_022:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "Processing 2/4: BraTS20_Training_023\n",
            "Loading files from /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_023:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "Processing 3/4: BraTS20_Training_024\n",
            "Loading files from /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_024:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "Processing 4/4: BraTS20_Training_025\n",
            "Loading files from /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_025:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\n",
            "Processing test data...\n",
            "Processing 1/5: BraTS20_Training_026\n",
            "Loading files from /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_026:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "Processing 2/5: BraTS20_Training_027\n",
            "Loading files from /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_027:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "Processing 3/5: BraTS20_Training_028\n",
            "Loading files from /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_028:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "Processing 4/5: BraTS20_Training_029\n",
            "Loading files from /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_029:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "Processing 5/5: BraTS20_Training_030\n",
            "Loading files from /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/Dataset/MICCAI_BraTS2020_TrainingData/BraTS20_Training_030:\n",
            "FLAIR: True\n",
            "T1: True\n",
            "T1ce: True\n",
            "T2: True\n",
            "Seg: True\n",
            "\n",
            "Dataset creation complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/train.py --model sequential --data brats20_new --epochs 200 --save_dir brats20_new --checkpoint False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAITlVlDuemX",
        "outputId": "5f40abdc-7db5-4be4-c1a1-f3fb7bc2c241"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gnumpy: failed to import cudamat. Using npmat instead. No GPU will be used.\n",
            "Warning: gnumpy not found, using numpy instead\n",
            "Warning: climin not found, using basic training loop\n",
            "Warning: breze not found, using basic reporting\n",
            "Using device: cuda\n",
            "Loading dataset: brats20_new\n",
            "Loading dataset: brats20_new\n",
            "Looking for dataset at: /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/data/datasets/brats20_new.hdf5\n",
            "Data shapes:\n",
            "Train: torch.Size([70, 4, 120, 120, 78]), torch.Size([70, 120, 120, 78])\n",
            "Valid: torch.Size([15, 4, 120, 120, 78]), torch.Size([15, 120, 120, 78])\n",
            "Test: torch.Size([15, 4, 120, 120, 78]), torch.Size([15, 120, 120, 78])\n",
            "\n",
            "Class distribution:\n",
            "Class 0 (non-tumor): 50.52%\n",
            "Class 1 (tumor): 49.48%\n",
            "Using weighted loss with weights: [0.98961407 1.0106063 ]\n",
            "Warning: Checkpoint not found at False\n",
            "\n",
            "Epoch 1/600\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 0: loss = 0.6933\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 10: loss = 0.6933\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 20: loss = 0.6934\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 30: loss = 0.6933\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Training Loss: 0.6933\n",
            "Validation Loss: 0.6933\n",
            "\n",
            "Epoch 2/600\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 0: loss = 0.6932\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 10: loss = 0.6931\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 20: loss = 0.6931\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 30: loss = 0.6933\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Training Loss: 0.6932\n",
            "Validation Loss: 0.6933\n",
            "\n",
            "Epoch 3/600\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 0: loss = 0.6932\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 10: loss = 0.6930\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 20: loss = 0.6931\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 30: loss = 0.6933\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Training Loss: 0.6932\n",
            "Validation Loss: 0.6933\n",
            "\n",
            "Epoch 4/600\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 0: loss = 0.6932\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 10: loss = 0.6930\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 20: loss = 0.6931\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 30: loss = 0.6933\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Training Loss: 0.6932\n",
            "Validation Loss: 0.6933\n",
            "\n",
            "Epoch 5/600\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 0: loss = 0.6932\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 10: loss = 0.6930\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 20: loss = 0.6931\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 30: loss = 0.6933\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Training Loss: 0.6932\n",
            "Validation Loss: 0.6933\n",
            "\n",
            "Epoch 6/600\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 0: loss = 0.6932\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 10: loss = 0.6930\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 20: loss = 0.6931\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 30: loss = 0.6933\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Training Loss: 0.6932\n",
            "Validation Loss: 0.6933\n",
            "\n",
            "Epoch 7/600\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 0: loss = 0.6932\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 10: loss = 0.6930\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 20: loss = 0.6931\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 30: loss = 0.6933\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Training Loss: 0.6932\n",
            "Validation Loss: 0.6933\n",
            "\n",
            "Epoch 8/600\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 0: loss = 0.6933\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 10: loss = 0.6930\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 20: loss = 0.6931\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 30: loss = 0.6933\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Training Loss: 0.6932\n",
            "Validation Loss: 0.6933\n",
            "\n",
            "Epoch 9/600\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 0: loss = 0.6932\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 10: loss = 0.6930\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 20: loss = 0.6931\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 30: loss = 0.6933\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Training Loss: 0.6932\n",
            "Validation Loss: 0.6933\n",
            "\n",
            "Epoch 10/600\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 0: loss = 0.6932\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 10: loss = 0.6930\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 20: loss = 0.6931\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 30: loss = 0.6933\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Training Loss: 0.6932\n",
            "Validation Loss: 0.6933\n",
            "\n",
            "Epoch 11/600\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 0: loss = 0.6933\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 10: loss = 0.6930\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 20: loss = 0.6931\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 30: loss = 0.6933\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Training Loss: 0.6932\n",
            "Validation Loss: 0.6933\n",
            "\n",
            "Epoch 12/600\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 0: loss = 0.6932\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 10: loss = 0.6930\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 20: loss = 0.6931\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 30: loss = 0.6933\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Training Loss: 0.6932\n",
            "Validation Loss: 0.6933\n",
            "\n",
            "Epoch 13/600\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 0: loss = 0.6932\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 10: loss = 0.6930\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 20: loss = 0.6931\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 30: loss = 0.6933\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Training Loss: 0.6932\n",
            "Validation Loss: 0.6933\n",
            "\n",
            "Epoch 14/600\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 0: loss = 0.6933\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 10: loss = 0.6930\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 20: loss = 0.6931\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 30: loss = 0.6933\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Training Loss: 0.6932\n",
            "Validation Loss: 0.6933\n",
            "\n",
            "Epoch 15/600\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 0: loss = 0.6932\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 10: loss = 0.6930\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 20: loss = 0.6930\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 30: loss = 0.6933\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Training Loss: 0.6932\n",
            "Validation Loss: 0.6933\n",
            "\n",
            "Epoch 16/600\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 0: loss = 0.6933\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 10: loss = 0.6930\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 20: loss = 0.6931\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 30: loss = 0.6933\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Training Loss: 0.6932\n",
            "Validation Loss: 0.6933\n",
            "\n",
            "Epoch 17/600\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 0: loss = 0.6932\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 10: loss = 0.6930\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 20: loss = 0.6930\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 30: loss = 0.6933\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Training Loss: 0.6932\n",
            "Validation Loss: 0.6933\n",
            "\n",
            "Epoch 18/600\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 0: loss = 0.6932\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 10: loss = 0.6930\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 20: loss = 0.6931\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 30: loss = 0.6933\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Training Loss: 0.6932\n",
            "Validation Loss: 0.6933\n",
            "\n",
            "Epoch 19/600\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 0: loss = 0.6932\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 10: loss = 0.6930\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 20: loss = 0.6930\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 30: loss = 0.6933\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Training Loss: 0.6932\n",
            "Validation Loss: 0.6933\n",
            "\n",
            "Epoch 20/600\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 0: loss = 0.6932\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 10: loss = 0.6930\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 20: loss = 0.6930\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 30: loss = 0.6933\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Training Loss: 0.6932\n",
            "Validation Loss: 0.6933\n",
            "\n",
            "Epoch 21/600\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 0: loss = 0.6932\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 10: loss = 0.6930\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 20: loss = 0.6932\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 30: loss = 0.6933\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Training Loss: 0.6932\n",
            "Validation Loss: 0.6933\n",
            "\n",
            "Epoch 22/600\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 0: loss = 0.6932\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 10: loss = 0.6931\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 20: loss = 0.6931\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 30: loss = 0.6933\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Training Loss: 0.6932\n",
            "Validation Loss: 0.6933\n",
            "\n",
            "Epoch 23/600\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 0: loss = 0.6932\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 10: loss = 0.6930\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 20: loss = 0.6931\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 30: loss = 0.6933\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Training Loss: 0.6932\n",
            "Validation Loss: 0.6933\n",
            "\n",
            "Epoch 24/600\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 0: loss = 0.6932\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 10: loss = 0.6930\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 20: loss = 0.6931\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 30: loss = 0.6933\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Training Loss: 0.6932\n",
            "Validation Loss: 0.6934\n",
            "\n",
            "Epoch 25/600\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 0: loss = 0.6932\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 10: loss = 0.6930\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 20: loss = 0.6931\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 30: loss = 0.6933\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Training Loss: 0.6932\n",
            "Validation Loss: 0.6933\n",
            "\n",
            "Epoch 26/600\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 0: loss = 0.6932\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 10: loss = 0.6929\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 20: loss = 0.6930\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 30: loss = 0.6933\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Training Loss: 0.6932\n",
            "Validation Loss: 0.6933\n",
            "\n",
            "Epoch 27/600\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 0: loss = 0.6932\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 10: loss = 0.6930\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 20: loss = 0.6930\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 30: loss = 0.6933\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Training Loss: 0.6932\n",
            "Validation Loss: 0.6933\n",
            "\n",
            "Epoch 28/600\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Batch 0: loss = 0.6932\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n",
            "Input shape: torch.Size([2, 4, 120, 120, 78])\n",
            "Model output shape: torch.Size([2, 2, 120, 120, 78])\n",
            "Reshaped output shape: torch.Size([2246400, 2])\n",
            "Target shape: torch.Size([2246400])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python \"/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/evaluate.py\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbJEPpvkDxnc",
        "outputId": "b67f6260-0d91-41f2-fbc8-3e74143366a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gnumpy: failed to import cudamat. Using npmat instead. No GPU will be used.\n",
            "Warning: gnumpy not found, using numpy instead\n",
            "Warning: climin not found, using basic training loop\n",
            "Warning: breze not found, using basic reporting\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/evaluate.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(model_path)\n",
            "Loading dataset: brats20_small\n",
            "Looking for dataset at: /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/data/datasets/brats20_small.hdf5\n",
            "Data shapes:\n",
            "Train: torch.Size([21, 4, 120, 120, 78]), torch.Size([21, 120, 120, 78])\n",
            "Valid: torch.Size([4, 4, 120, 120, 78]), torch.Size([4, 120, 120, 78])\n",
            "Test: torch.Size([5, 4, 120, 120, 78]), torch.Size([5, 120, 120, 78])\n",
            "\n",
            "Sample 0:\n",
            "Dice Score: 0.6411\n",
            "IoU Score: 0.4718\n",
            "\n",
            "Sample 1:\n",
            "Dice Score: 0.5972\n",
            "IoU Score: 0.4257\n",
            "\n",
            "Sample 2:\n",
            "Dice Score: 0.6486\n",
            "IoU Score: 0.4800\n",
            "\n",
            "Sample 3:\n",
            "Dice Score: 0.6604\n",
            "IoU Score: 0.4930\n",
            "\n",
            "Sample 4:\n",
            "Dice Score: 0.6427\n",
            "IoU Score: 0.4735\n",
            "\n",
            "Overall Evaluation Results:\n",
            "Average Dice Score: 0.6380 ± 0.0215\n",
            "Average IoU Score: 0.4688 ± 0.0228\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create directories if they don't exist\n",
        "!mkdir -p \"/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/models\"\n",
        "!mkdir -p \"/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/results\"\n",
        "\n",
        "# Copy model files\n",
        "!cp -r /content/models/*.pth \"/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/models/\"\n",
        "\n",
        "# Copy results (visualizations)\n",
        "!cp -r /content/results/* \"/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/results/\"\n",
        "\n",
        "print(\"Files saved to your Google Drive!\")\n",
        "\n",
        "# List the saved files\n",
        "print(\"\\nSaved model files:\")\n",
        "!ls -l \"/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/models\"\n",
        "\n",
        "print(\"\\nSaved result files:\")\n",
        "!ls -l \"/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/results\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OnXZBI8J4OF",
        "outputId": "d77edd45-7372-48fe-c147-3f3acb9b4913"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files saved to your Google Drive!\n",
            "\n",
            "Saved model files:\n",
            "total 8397\n",
            "-rw------- 1 root root 715554 Dec  7 17:25 best_model.pth\n",
            "drwx------ 2 root root   4096 Dec  6 09:07 brats_fold0\n",
            "-rw------- 1 root root 715898 Dec  7 17:25 checkpoint_epoch_100.pth\n",
            "-rw------- 1 root root 715870 Dec  7 17:25 checkpoint_epoch_10.pth\n",
            "-rw------- 1 root root 715870 Dec  7 17:25 checkpoint_epoch_20.pth\n",
            "-rw------- 1 root root 715870 Dec  7 17:25 checkpoint_epoch_30.pth\n",
            "-rw------- 1 root root 715870 Dec  7 17:25 checkpoint_epoch_40.pth\n",
            "-rw------- 1 root root 715870 Dec  7 17:25 checkpoint_epoch_50.pth\n",
            "-rw------- 1 root root 715870 Dec  7 17:25 checkpoint_epoch_60.pth\n",
            "-rw------- 1 root root 715870 Dec  7 17:25 checkpoint_epoch_70.pth\n",
            "-rw------- 1 root root 715870 Dec  7 17:25 checkpoint_epoch_80.pth\n",
            "-rw------- 1 root root 715870 Dec  7 17:25 checkpoint_epoch_90.pth\n",
            "-rw------- 1 root root 715758 Dec  7 17:25 sequential_best.pth\n",
            "\n",
            "Saved result files:\n",
            "total 564\n",
            "-rw------- 1 root root  72005 Dec  7 17:25 sample_0_slice_39.png\n",
            "-rw------- 1 root root  68023 Dec  7 17:25 sample_1_slice_39.png\n",
            "-rw------- 1 root root 290579 Dec  7 17:25 sample_2_slice_39.png\n",
            "-rw------- 1 root root  67822 Dec  7 17:25 sample_3_slice_39.png\n",
            "-rw------- 1 root root  78038 Dec  7 17:25 sample_4_slice_39.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tabulate psutil\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQ3tUUIIGdOr",
        "outputId": "a9a0be7b-a1ff-43fa-bee8-2f0a119fb930"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (0.9.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (5.9.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/comparison_metrics.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPmmrSCMNLBb",
        "outputId": "03e4ec9d-1919-4b11-8ba6-e52a3a882837"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gnumpy: failed to import cudamat. Using npmat instead. No GPU will be used.\n",
            "Warning: gnumpy not found, using numpy instead\n",
            "Warning: climin not found, using basic training loop\n",
            "Warning: breze not found, using basic reporting\n",
            "Using device: cuda\n",
            "Loading model from: /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/models/sequential_best.pth\n",
            "/content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/comparison_metrics.py:131: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(model_path, map_location=device)\n",
            "Loading test data for performance metrics...\n",
            "Loading dataset: brats20_small\n",
            "Looking for dataset at: /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/data/datasets/brats20_small.hdf5\n",
            "Data shapes:\n",
            "Train: torch.Size([21, 4, 120, 120, 78]), torch.Size([21, 120, 120, 78])\n",
            "Valid: torch.Size([4, 4, 120, 120, 78]), torch.Size([4, 120, 120, 78])\n",
            "Test: torch.Size([5, 4, 120, 120, 78]), torch.Size([5, 120, 120, 78])\n",
            "Test data shapes - Input: torch.Size([5, 4, 120, 120, 78]), Target: torch.Size([5, 120, 120, 78])\n",
            "Calculating performance metrics...\n",
            "\n",
            "Sample 0 raw output:\n",
            "Output shape: torch.Size([1, 2, 120, 120, 78])\n",
            "Output min/max: -0.6100/0.0725\n",
            "\n",
            "Sample 0 processed:\n",
            "Target unique values: [0. 1.]\n",
            "Prediction unique values: [0 1]\n",
            "Prediction shape: torch.Size([120, 120, 78]), Target shape: torch.Size([120, 120, 78])\n",
            "Saved visualization for sample 0 to: /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/models/visualizations/sample_0_prediction.png\n",
            "\n",
            "Sample 1 raw output:\n",
            "Output shape: torch.Size([1, 2, 120, 120, 78])\n",
            "Output min/max: -0.3144/0.0688\n",
            "\n",
            "Sample 1 processed:\n",
            "Target unique values: [0. 1.]\n",
            "Prediction unique values: [0 1]\n",
            "Prediction shape: torch.Size([120, 120, 78]), Target shape: torch.Size([120, 120, 78])\n",
            "Saved visualization for sample 1 to: /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/models/visualizations/sample_1_prediction.png\n",
            "\n",
            "Sample 2 raw output:\n",
            "Output shape: torch.Size([1, 2, 120, 120, 78])\n",
            "Output min/max: -0.4006/0.0714\n",
            "\n",
            "Sample 2 processed:\n",
            "Target unique values: [0. 1.]\n",
            "Prediction unique values: [0 1]\n",
            "Prediction shape: torch.Size([120, 120, 78]), Target shape: torch.Size([120, 120, 78])\n",
            "Saved visualization for sample 2 to: /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/models/visualizations/sample_2_prediction.png\n",
            "\n",
            "Sample 3 raw output:\n",
            "Output shape: torch.Size([1, 2, 120, 120, 78])\n",
            "Output min/max: -0.3754/0.0765\n",
            "\n",
            "Sample 3 processed:\n",
            "Target unique values: [0. 1.]\n",
            "Prediction unique values: [0 1]\n",
            "Prediction shape: torch.Size([120, 120, 78]), Target shape: torch.Size([120, 120, 78])\n",
            "\n",
            "Sample 4 raw output:\n",
            "Output shape: torch.Size([1, 2, 120, 120, 78])\n",
            "Output min/max: -0.3956/0.0711\n",
            "\n",
            "Sample 4 processed:\n",
            "Target unique values: [0. 1.]\n",
            "Prediction unique values: [0 1]\n",
            "Prediction shape: torch.Size([120, 120, 78]), Target shape: torch.Size([120, 120, 78])\n",
            "\n",
            "Model Metrics:\n",
            "=============\n",
            "\n",
            "Architecture Details:\n",
            "Architecture Type: 3D CNN\n",
            "Number of Parameters: 58,978\n",
            "Input Dimensions: 120x120x78\n",
            "Number of Input Channels: 4\n",
            "\n",
            "Computational Metrics:\n",
            "Inference Time: 9.14ms ± 28.24ms\n",
            "Memory Usage: 657.95 MB\n",
            "Training Epochs: 1\n",
            "Best Loss: 0.6936455368995667\n",
            "\n",
            "Performance Metrics:\n",
            "Dice Score: 0.6380 ± 0.0215\n",
            "IoU Score: 0.4688 ± 0.0228\n",
            "Precision: 0.5303 ± 0.0269\n",
            "Recall: 0.8022 ± 0.0218\n",
            "Accuracy: 0.5128 ± 0.0210\n",
            "\n",
            "Metrics saved to: /content/drive/MyDrive/RT-MyCopy/CNNbasedMedicalSegmentation/models/cnn_metrics.txt\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1DIrF_xMIHFaL1v9O2kGD-mEfn05LHD1M",
      "authorship_tag": "ABX9TyMG6AgVmu8PXi9da6LzzxC9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}